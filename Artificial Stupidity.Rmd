---
title: "Artificial Stupidity"
author: "Minghao Du"
date: "10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())
gc()

load_pkgs <-
  function(packages = c(),
           basic.packages = c(
             "package:stats",
             "package:graphics",
             "package:grDevices",
             "package:utils",
             "package:datasets",
             "package:methods",
             "package:base"
           )) {
    package.list <-
      search()[ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]
    package.list <- setdiff(package.list, basic.packages)
    if (length(package.list) > 0)
      for (package in package.list)
        detach(package, character.only = TRUE)
    installed_packages <- packages %in% rownames(installed.packages())
    if (any(installed_packages == FALSE)) {
      install.packages(packages[!installed_packages], dependencies = T)
    }
    invisible(lapply(packages, library, character.only = TRUE))
  }


pkg_list <- c(
  "plotly", 
  "tidyverse", 
  "readxl", 
  "GGally", 
  "psych", 
  "janitor", 
  "e1071", 
  "lubridate", 
  "fastDummies", 
  "xgboost", 
  "tensorflow", 
  "keras", 
  "reticulate", 
  "gender", 
  "stringr", 
  "caret", 
  "textstem", 
  "tm", 
  "tidytext", 
  "lhs", 
  "smoof", 
  "mlrMBO", 
  "DiceKriging", 
  "mice", 
  "parallel", 
  "forcats", 
  "Boruta", 
  "textfeatures", 
  "cluster", 
  "rFerns")
load_pkgs(pkg_list)

# install_miniconda()
# https://www.tensorflow.org/install/source_windows 
# https://www.tensorflow.org/install/gpu#hardware_requirements 
# https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow 
# conda_create(envname = "r-reticulate", packages = "tensorflow-gpu", python_version = "3.9")
seed <- 123
saveProcessedData <- F
cores <- detectCores() - 1
'%!in%' <- function(x,y)!('%in%'(x,y))
use_condaenv("r-reticulate")
```

```{r}
writeSubmit <- function(pred) {
  submissionFile = data.frame(id = scoringData$id, price = pred)
  write.csv(submissionFile, 'submission.csv', row.names = F)
}

rawData <- read_csv('./input/rentlala2021/analysisData.csv')

scoringData <- read_csv('./input/rentlala2021/scoringData.csv')

compare_df_cols(rawData, scoringData) %>%
  filter(rawData != scoringData |
           rawData %>% is.na() | scoringData %>% is.na())

rawData %>% mutate(license = license %>% as.logical()) -> rawData
scoringData  %>% mutate(zipcode = zipcode %>% as.numeric()) -> scoringData

compare_df_cols(rawData, scoringData) %>%
  filter(rawData != scoringData | rawData %>% is.na() | scoringData %>% is.na())
```



```{r}

pricedScoringData <- scoringData %>% mutate(price = -1)

allData <- rawData %>% bind_rows(pricedScoringData) 


extractID <- allData %>% select(id)

allData <- allData %>% select(-id)

numericCols <- allData %>% select(is.numeric) %>% colnames()
boolCols <- allData %>% select(is.logical) %>% colnames()
dateCols <- allData %>% select(is.Date) %>% colnames()
charCols <- allData %>% select(is.character) %>% colnames()
longCharCols <-
  allData[charCols] %>% 
  select(c(name, 
      summary, 
      space, 
      description, 
      neighborhood_overview, 
      notes, 
      transit, 
      access, 
      interaction, 
      house_rules, 
      host_about
  )) %>% 
  colnames()
factorCharCols <- 
  allData[charCols] %>% 
  select(-c(name, 
      summary, 
      space, 
      description, 
      neighborhood_overview, 
      notes, 
      transit, 
      access, 
      interaction, 
      house_rules, 
      host_about
  )) %>% 
  select(-c(
    host_name, 
    host_verifications, 
    host_response_time,
    calendar_updated, 
    host_response_rate, 
    host_acceptance_rate, 
    amenities
  )) %>% 
  colnames()

rateCols <- allData %>% 
  select(c(host_response_rate, host_acceptance_rate)) %>% 
  colnames()


tempCopy <- allData

```



```{r}

allData<- tempCopy

## TODO: handle outliers 
## TODO: create mean price cols for different factors 
## TODO: reconsider factor reduction 
## TODO: reconsider impute data 
## TODO: 


allData[charCols] <- allData[charCols] %>% mutate_all(funs(enc2utf8(.)))


##### Process zipcode column 

mostCommonZip <- allData %>% 
  select(c(neighbourhood_cleansed, neighbourhood_group_cleansed, city, zipcode)) %>% 
  group_by(neighbourhood_cleansed, zipcode) %>% 
  summarise(count = n()) %>% 
  filter(count == max(count)) %>% 
  ungroup()

getZip <- function(neighbourhood_cleansed){
  mostCommonZip %>% filter(neighbourhood_cleansed == neighbourhood_cleansed) %>% select(zipcode) %>% pull(zipcode)
}

allData <- allData %>% mutate(zipcode = ifelse(is.na(zipcode), getZip(neighbourhood_cleansed), zipcode)) %>% mutate(zipcode = zipcode %>% as.factor())



##### Converte rate cols to rates 

allData[rateCols] <- allData[rateCols] %>% 
  mutate(host_response_rate = gsub("N/A","0%", host_response_rate)) %>% 
  mutate(host_acceptance_rate = gsub("N/A","0%", host_acceptance_rate)) %>% 
  mutate(host_response_rate = gsub("%","", host_response_rate)) %>% 
  mutate(host_acceptance_rate = gsub("%","", host_acceptance_rate)) %>% 
  mutate_all(as.numeric) %>% 
  mutate_each(funs(./100)) %>% 
  replace(is.na(.),0)


temp <- allData


##### Handle/impute NA value for bool and numeric columns

allData <- temp

# allData %>% ggplot(aes(weekly_price)) + geom_density()
# allData %>% ggplot(aes(monthly_price)) + geom_density()

allData[boolCols] <- allData[boolCols] %>% replace(is.na(.),F)

reservedNumCols <- allData %>% select(c(square_feet, weekly_price, monthly_price)) %>% colnames()

allData[numericCols[numericCols %!in% reservedNumCols]] <- 
  allData[numericCols[numericCols %!in% reservedNumCols]] %>% replace(is.na(.),0)

allData <- allData %>% mutate(square_feet = ifelse(is.na(square_feet), 0, square_feet))
allData <- allData %>% mutate(weekly_price = ifelse(is.na(weekly_price), 0, weekly_price))
allData <- allData %>% mutate(monthly_price = ifelse(is.na(monthly_price), 0, monthly_price))


# allData <- allData %>% mutate(square_feet = ifelse(square_feet == 0, NA, square_feet))
# allData <- allData %>% mutate(weekly_price = ifelse(weekly_price == 0, NA, weekly_price))
# allData <- allData %>% mutate(monthly_price = ifelse(monthly_price == 0, NA, monthly_price))
# 
# impute <- allData %>% select(-price) %>% select(where(is.numeric)) %>% colnames()
# tempData <-
#   parlmice(
#     data = allData[impute],
#     m = ncol(allData[impute]),
#     # n.core = cores,
#     # n.imp.core = ncol(allData[impute]),
#     cluster.seed = seed,
#     # seed = seed,
#     maxit = 100,
#     method = "rf",
#     print = FALSE
#   )
# 
# allData[impute] <- complete(tempData)

# allData %>% ggplot(aes(weekly_price)) + geom_density()
# allData %>% ggplot(aes(monthly_price)) + geom_density()



temp <- allData


##### Process factor columns 

allData <- temp

# allData <- allData %>% select(-factorCharCols) %>%
#   add_column(allData[factorCharCols] %>%
#   replace(is.na(.),"N/A") %>%
#   dummy_cols(select_columns = factorCharCols, remove_selected_columns = T) %>%
#   clean_names())
#   %>%
#   select_if(~sum(.) != 1))
  
allData[factorCharCols] <- allData[factorCharCols] %>%
  replace(is.na(.), "N/A") %>%
  mutate_all(as.factor)

## allData <- allData %>% select(-c(host_location, host_neighbourhood, country_code, smart_location, city, street, country, state, market)) 

## reduceLevelCols <- allData %>% select(c(neighbourhood_cleansed, property_type, zipcode)) %>% colnames()


allData <- allData %>% select(-c(country_code, country, state, market)) 

# reduceLevelCols <- allData %>% select(c(host_location, host_neighbourhood, street, neighbourhood_cleansed, city, smart_location, property_type, zipcode)) %>% colnames()
# 
# allData[reduceLevelCols] <- allData[reduceLevelCols] %>% mutate_all(funs(fct_lump(., prop = 0.001)))



##### Conject new columns 

## mean price 

mean_price <- allData %>% 
  filter(price > -1) %>% 
  group_by(neighbourhood_cleansed = neighbourhood_cleansed) %>%
    summarize(record_count_c = n(), 
              price_mean_c = mean(price))

allData <- allData %>% left_join(mean_price, by = c("neighbourhood_cleansed" = "neighbourhood_cleansed"))
allData[is.na(allData$price_mean_c),]$price_mean_c = mean(allData["price" > -1, ]$price_mean_c, na.rm = TRUE)

mean_price2 <- allData %>% 
  filter(price > -1) %>% 
  group_by(neighbourhood_group_cleansed = neighbourhood_group_cleansed) %>%
  summarize(price_mean_ngc = mean(price))

allData <- allData %>% left_join(mean_price2, by = c("neighbourhood_group_cleansed" = "neighbourhood_group_cleansed"))

mean_price3 <- allData %>% 
  filter(price > -1) %>% 
  group_by(zipcode = zipcode) %>%
  summarize(price_mean_zip = mean(price))

allData <- allData %>% left_join(mean_price3, by = c("zipcode" = "zipcode"))
allData[is.na(allData$price_mean_zip),]$price_mean_zip = mean(allData["price" > -1, ]$price_mean_zip, na.rm = TRUE)

## sex 

allData %>% select(host_name) %>% c() -> names 

allData <- allData %>%
  left_join(gender(names$host_name) %>%
              distinct() %>%
              select(c(name, proportion_male, proportion_female)),
            by = c("host_name" = "name"))

## lat-long 

ZipCodeSourceFile = "http://download.geonames.org/export/zip/US.zip"
tempFile <- tempfile()
download.file(ZipCodeSourceFile , tempFile)
ZipCodes <- read.table(unz(tempFile, "US.txt"), sep="\t")
unlink(tempFile)
names(ZipCodes) = c("CountryCode", "zip", "PlaceName", 
"AdminName1", "AdminCode1", "AdminName2", "AdminCode2", 
"AdminName3", "AdminCode3", "latitude", "longitude", "accuracy") 
ZipCodes <- ZipCodes %>% mutate(zip = as.factor(zip))
allData <- allData %>% 
  left_join(
    ZipCodes %>% 
      select(c(zip, 
               PlaceName, 
               AdminName2, 
               latitude, 
               longitude)), by = c("zipcode"="zip")
  )

allData <- allData %>% mutate(PlaceName = PlaceName %>% as.factor(), 
                              AdminName2 = AdminName2 %>% as.factor())

##### process host verification and amenities 

allData <- allData %>% 
  mutate(host_verifications = gsub("\\[|\\]|\\'|\\,", "", host_verifications)) %>% 
  mutate(vari_count = strsplit(host_verifications, " ") %>% lengths())

vari_list <- allData %>% 
  select(host_verifications) %>% 
  lapply(function(x) unique(trimws(unlist(strsplit(x, " ")))))

for(w in 1:length(vari_list[[1]])) {
  # print(vari_list[[1]][w])
  new <- grepl(pattern = vari_list[[1]][w], x = allData$host_verifications, fixed = TRUE)
  allData[paste(vari_list[[1]][w], "_vari")] <- new
}

allData <- allData %>% select(-host_verifications)

allData <- allData %>% 
  mutate(amenities_count = strsplit(amenities, ",") %>% lengths()) 

amen_list <- allData %>% 
  select(amenities) %>% 
  mutate(amenities = gsub("\\.", "", amenities)) %>% 
  lapply(function(x) unique(trimws(unlist(strsplit(x, ",")))))

for(w in 1:length(amen_list[[1]])) {
  new <- grepl(pattern = amen_list[[1]][w], x = allData$amenities, fixed = TRUE)
  allData[paste(amen_list[[1]][w], "_amen")] <- new
}

allData <- allData %>% select(-amenities) %>% clean_names()


##### process text duration columns 

allData <- allData %>%
  mutate(host_response_time = gsub("within a ", "", host_response_time)) %>%
  mutate(host_response_time = gsub("within an ", "", host_response_time)) %>%
  mutate(host_response_time = gsub("few hours", "12", host_response_time)) %>%
  mutate(host_response_time = gsub("hour", "1", host_response_time)) %>%
  mutate(host_response_time = gsub("a few days or more", "48", host_response_time)) %>%
  mutate(host_response_time = gsub("day", "24", host_response_time)) %>%
  mutate(host_response_time = replace_na(host_response_time, "N/A")) %>% 
  mutate(host_response_time = gsub("N/A", "96", host_response_time)) %>%
  mutate(host_response_time = as.numeric(host_response_time))

allData <- allData %>% 
  mutate(calendar_updated = gsub(" ago", "", calendar_updated)) %>% 
  mutate(calendar_updated = gsub("today", "0", calendar_updated)) %>% 
  mutate(calendar_updated = gsub("yesterday", "1", calendar_updated)) %>% 
  mutate(calendar_updated = case_when(
    grepl("days", calendar_updated) ~ as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated)) %>% as.character(), 
    grepl("weeks", calendar_updated) ~ as.character(as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated))*7),
    grepl("months", calendar_updated) ~ as.character(as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated))*30), 
    grepl("a week", calendar_updated) ~ "7",
    grepl("week", calendar_updated) ~ "7",
    grepl("never", calendar_updated) ~ "3000",
    TRUE ~ as.character(calendar_updated)
  )) %>% 
  mutate(calendar_updated = as.numeric(calendar_updated))


##### process date columns 

allData[dateCols] <- allData %>% 
  select(dateCols) %>% 
  mutate_all(funs(max(., na.rm = TRUE) - .)) %>% 
  mutate_all(as.numeric)



##### Text mining 

prep_fun <- function(x) {
    x %>%
      str_to_lower() %>%
      str_replace_all("[^[:alnum:]]", " ") %>%
      {gsub(patter = "\\d", replace = " ", .)} %>%
      removeWords(stopwords()) %>%
      {gsub(patter = "\\b[A-z]\\b{1}", replace = " ", .)} %>%
      str_replace_all("\\s+", " ") %>%
      lemmatize_strings()
  }

allData[longCharCols] <- allData[longCharCols] %>% replace(is.na(.), "")

# allData <- allData %>%
#   bind_cols(allData[longCharCols] %>%
#               mutate_each(funs(str_count)) %>%
#               rename_all(function(x) paste0(x, "_wcount")))

allText <- NULL

for(col in longCharCols) allText <- paste(allText, " ", allData[[col]])

tex_feat <- textfeatures(allText)

allData <- allData %>% bind_cols(tex_feat)

# allData[longCharCols] <- allData[longCharCols] %>%
#   mutate_all(funs(prep_fun(.))) %>%
#   replace(is.na(.), "")

# textColsAgg <- allData[longCharCols] %>%
#   mutate_all(funs(prep_fun(.))) %>%
#   replace(is.na(.), "") %>%
#   unite(allText) %>%
#   add_column(ID = extractID$id) %>%
#   relocate(ID)
# 
# stemmedText <- textColsAgg %>%
#   unnest_tokens(input = allText, output = word) %>%
#   anti_join(stop_words)


## TODO: generate new numeric cols for long text cols 
## TODO: transform long text cols to numeric value 
```
```{r}
copyData <- allData

allData <- allData %>% cbind( copyData %>%
  select(where(is.numeric)) %>%
  select(-price) %>%
  mutate_all(function(x) x^2) %>%
  setNames(paste0(names(.), "_2pow")))
allData <- allData %>% cbind( copyData %>%
  select(where(is.numeric)) %>%
  select(-price) %>%
  mutate_all(function(x) x^3) %>%
  setNames(paste0(names(.), "_3pow")))

numCols <- allData %>% select(is.numeric) %>% colnames()
facCols <- allData %>% select(is.factor) %>% colnames()
boolCols <- allData %>% select(is.logical) %>% colnames()

allData[numCols] <- allData[numCols] %>% 
  replace(is.na(.),0) %>% 
  mutate_at(vars(-price), funs(scale))

allData[facCols] <- allData[facCols] %>%
  mutate_all(funs(as.numeric(.)-1))

allData[boolCols] <- allData[boolCols] %>% 
  mutate_all(funs(as.numeric(.)))

remove0var <- function(dat) {
    out <- lapply(dat, function(x) length(unique(x)))
    want <- which(!out > 1)
    name <- unlist(want) %>% names()
    print(name)
    dat %>% select(-name)
}

allData <- allData %>% remove0var() 

```


```{r}
beforeCluster <- allData 

allData <- beforeCluster %>% 
  # head(10000) %>% 
  select(!is.character)

# distance = dist(allData )
# 
# mydata.hclust = hclust(distance)
# plot(mydata.hclust)
# plot(mydata.hclust,labels=allData$price,main='Default from hclust')
# plot(mydata.hclust,hang=-1, labels=allData$price,main='Default from hclust')
# 
# mydata.hclust<-hclust(distance,method="average") 
# plot(mydata.hclust,hang=-1) 
# 
# member = cutree(mydata.hclust,3)
# table(member)
# 
# aggregate(allData %>% select(!is.character) %>% select(-price),list(member),mean)
# plot(silhouette(cutree(mydata.hclust,3), distance))


wss <- (nrow(allData)-1)*sum(apply(allData,2,var))
for (i in 2:20) {
  set.seed(seed)
  print(i)
  clu <- kmeans(allData %>% select(-price), centers=i)
  wss[i] <- sum(clu$withinss) 
  # p <- allData %>% 
  #   select(price) %>% 
  #   mutate(cluster = clu$cluster %>% as.factor()) %>% 
  #   ggplot(aes(x = price, color = cluster)) + geom_density()
  # p %>% ggplotly() %>% print()
  }
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") %>% ggplotly()

set.seed(seed)
kc <- kmeans(allData, centers=50)

beforeCluster %>% mutate(cluster = kc$cluster %>% as.factor()) -> afterCluster

mean_price_cluster <- afterCluster %>% 
  filter(price > -1) %>% 
  group_by(cluster = cluster) %>%
  summarize(price_mean_clus = mean(price))

afterCluster <- afterCluster %>% left_join(mean_price_cluster, by = c("cluster" = "cluster"))

pp <- afterCluster %>% select(c(price, cluster)) %>% ggplot(aes(x = price, color = cluster)) + geom_density()
pp %>% ggplotly()

allData <- afterCluster %>% mutate(cluster = cluster %>% as.numeric())

glimpse(allData)
allData$place_name
```


```{r}
# 
# 
# priceTemp <- allData %>% select(price)
# 
# pcaModel <- preProcess(x = allData %>% select(-price) %>% as.matrix(), method = 'pca', thresh = 0.9)
# # pcaModel <- preProcess(x = allData %>% select(-price), method = 'pca', pcaComp = 200)
# 
# allData <- predict(pcaModel, newdata = allData %>% select(-price))
# 
# allData$price <- priceTemp

trainData <- allData %>%
    select(!is.character) %>% 
    # add_column(ID = extractID$id) %>%
    # relocate(ID) %>%
    filter(price > -1) 
testData <- allData %>%
    select(!is.character) %>% 
    # add_column(ID = extractID$id) %>%
    # relocate(ID) %>%
    filter(price == -1) %>% select(-price)

### feature selection

boruta_output <- Boruta(price ~ ., data=trainData, pValue = 0.05, maxRuns = 500, doTrace = 2, getImp= getImpXgboost)
selectedCols <- boruta_output %>% getSelectedAttributes(withTentative = TRUE)

trainData <- trainData %>% select(c(price, selectedCols))
testData <- testData %>% select(selectedCols)



if (saveProcessedData) {
  
  write.csv(trainData,
            file("processedTrainData.csv",encoding="UTF-8"),
            row.names = F)
  write.csv(testData,
            file("processedTestData.csv",encoding="UTF-8"),
            row.names = F)
}



```

```{r eval=FALSE}
set.seed(seed)
knnTrain <- trainData %>% head(5000)

ctrl <- trainControl(
  method = "cv",
  number = 10,
  verboseIter = TRUE
)

tuneGrid <- expand.grid(
  k = seq(5, 20, by = 1)
)

modelKNN <- caret::train(
  price ~ .,
  data = knnTrain,
  method = 'knn',
  # preProcess = c("center", "scale"),
  trControl = ctrl,
  tuneGrid = tuneGrid, 
  verbose = TRUE
)

modelKNN
```

```{r}

BoostTrainData <- xgb.DMatrix(model.matrix(price ~ ., data = trainData),
                              label = as.matrix(trainData %>% select(price)))

obj.fun <- makeSingleObjectiveFunction(
  name = "xgb_cv_bayes",
  fn =   function(x) {
    set.seed(seed)
    print(x)
    cv <- xgb.cv(
      params = list(
        # booster          = "gbtree",
        eta                    = x["eta"],
        max_depth              = x["max_depth"],
        min_child_weight       = x["min_child_weight"],
        gamma                  = x["gamma"],
        lambda                 = x["lambda"],
        alpha                  = x["alpha"],
        subsample              = x["subsample"],
        colsample_bytree       = x["colsample_bytree"],
        max_delta_step         = x["max_delta_step"],
        tweedie_variance_power = x["tweedie_variance_power"],
        objective              = 'reg:tweedie',
        eval_metric            = 'rmse'
      ),
      data = BoostTrainData,
      nround = 7000,
      nthread = cores,
      nfold =  10,
      prediction = FALSE,
      showsd = TRUE,
      early_stopping_rounds = 5,
      verbose = 1,
      print_every_n = 500
    )
    cv$evaluation_log %>% pull(4) %>% min
  },
  par.set = makeParamSet(
    makeNumericParam("eta",                    lower = 0.005, upper = 0.36),
    makeNumericParam("gamma",                  lower = 1,     upper = 8),
    makeNumericParam("lambda",                 lower = 1,     upper = 8),
    makeNumericParam("alpha",                  lower = 1,     upper = 8),
    makeIntegerParam("max_depth",              lower = 2,     upper = 20),
    makeIntegerParam("min_child_weight",       lower = 1,     upper = 2000),
    makeNumericParam("subsample",              lower = 0.01,  upper = 1),
    makeNumericParam("colsample_bytree",       lower = 0.01,  upper = 1),
    makeNumericParam("max_delta_step",         lower = 0,     upper = 10),
    makeNumericParam("tweedie_variance_power", lower = 1,     upper = 2)
  ),
  minimize = TRUE
)

do_bayes <-
  function(n_design = NULL,
           opt_steps = NULL,
           of = obj.fun,
           seed = seed) {
    set.seed(seed)
    
    des <- generateDesign(n = n_design,
                          par.set = getParamSet(of),
                          fun = lhs::randomLHS)
    
    control <-
      makeMBOControl() %>% setMBOControlTermination(., iters = opt_steps)
    
    run <- mbo(
      fun = of,
      design = des,
      learner = makeLearner(
        "regr.km",
        predict.type = "se",
        covtype = "matern3_2",
        control = list(trace = FALSE)
      ),
      control = control,
      show.info = TRUE
    )
    
    opt_plot <- run$opt.path$env$path %>%
      mutate(Round = row_number()) %>%
      mutate(type = case_when(Round <= n_design ~ "Design",
                              TRUE ~ "mlrMBO optimization")) %>%
      ggplot(aes(x = Round, y = y, color = type)) +
      geom_point() +
      labs(title = "mlrMBO optimization") +
      ylab("-log(likelihood)")
    
    # print(run$x)
    
    return(list(run = run, plot = opt_plot))
  }

# des <- generateDesign(n=15,
#                       par.set = getParamSet(obj.fun),
#                       fun = lhs::randomLHS)

# kable(des, format = "html", digits = 4) %>%
#   kable_styling(font_size = 10) %>%
#   kable_material_dark()

runs <-
  do_bayes(
    n_design = 20,
    of = obj.fun,
    opt_steps = 20,
    seed = seed
  )

plot(runs$run)

best.params <- runs$run$x
# best.params <- list(
#         eta                    = 0.0151,
#         max_depth              = 18,
#         min_child_weight       = 948,
#         gamma                  = 1.58,
#         subsample              = 0.436,
#         colsample_bytree       = 0.829,
#         max_delta_step         = 8.47,
#         tweedie_variance_power = 1.49,
#         objective = 'reg:tweedie',
#         eval_metric = 'rmse'
#       )

set.seed(seed)
optimal.cv <- xgb.cv(
  params = best.params,
  data = BoostTrainData,
  nround = 7000,
  nthread = cores,
  nfold =  10,
  prediction = FALSE,
  showsd = TRUE,
  early_stopping_rounds = 5,
  verbose = 1,
  print_every_n = 100, 
  objective = 'reg:tweedie',
  eval_metric = 'rmse'
)

set.seed(seed)
model <-
  xgboost(
    params = best.params,
    data = BoostTrainData,
    nrounds = optimal.cv$best_ntreelimit
  )




# [mbo] 0: eta=0.0151; gamma=1.58; max_depth=18; min_child_weight=948; subsample=0.436; colsample_bytree=0.829; max_delta_step=8.47; tweedie_variance_power=1.49 : y = 47.3 : 2457.9 secs : initdesign

summary(model)

# xgb.importance(model)

pred <-
  predict(model, model.matrix(price~., testData %>% mutate(price = -1)) %>% xgb.DMatrix())

writeSubmit(pred)

```




```{r}

NetTrainX <- trainData %>% select(-price) %>% as.matrix() 
NetTrainY <- trainData %>% select(price) %>% as.matrix()

rmse <- function(y, y_hat){
  sqrt(mean((y - y_hat)^2))
}

inputSize <- dim(NetTrainX)[2] 
offsetSize <- 0.45
dropout <- 0.5
activate <- "relu"

scaleSize <- inputSize * offsetSize

model <- keras_model_sequential() %>%
  layer_dense(units = scaleSize*2, activation = activate, input_shape = dim(NetTrainX)[2]) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*4, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*8, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*4, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*2, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*0.5, activation = activate) %>%
  layer_dense(units = scaleSize*0.25, activation = activate) %>%
  layer_dense(units = 1, activation = activate)

model %>% compile(
   loss = "mse",
   optimizer =  "nadam", 
   metrics = c("mape","mse")
 )
 
model %>% summary()
```

```{r}
set.seed(seed)
model %>% fit(NetTrainX, NetTrainY, epochs = 100, batch_size = 128, validation_split = 0.2,verbose = 2)
 
scores <- model %>% evaluate(NetTrainX, NetTrainY, verbose = 0)
print(scores)
```


```{r}
summary(model)

pred <- predict(model, testData %>% as.matrix())

writeSubmit(pred)
```


```{r}

```



