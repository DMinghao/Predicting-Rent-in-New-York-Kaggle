---
title: "Artificial Stupidity Predicting NYC AirBnB Rent"
author: "Minghao Du"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: 
    latex_engine: xelatex
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro 

The objective of this project is to predict Airbnb rent based on 90 features. These features include various data types, and data cleaning and pre-processing is required before modeling. The result will be evaluated with RMSE, the lower the score is the better the model predicts. 

## Initiating R Environment 

The following code will initiate the R environment with required R packages and helper functions. Since the project will create an artificial neural network, TensorFlow and Keras is imported with miniconda, of which will facilitate any GPU computation that is needed for the network. Other than that, the flowing code also sets constant value for the entire project, including seed and number of cores. 

```{r echo=FALSE}
rm(list = ls())
gc()

downloader::source_url("https://raw.githubusercontent.com/DMinghao/Analysis_Pocketknife/main/R/init_env.R", downloader::sha_url("https://raw.githubusercontent.com/DMinghao/Analysis_Pocketknife/main/R/init_env.R"))

pkg_list <- c(
  "plotly", 
  "tidyverse", 
  "readxl", 
  "GGally", 
  "psych", 
  "janitor", 
  "e1071", 
  "lubridate", 
  "fastDummies", 
  "xgboost", 
  "tensorflow", 
  "keras", 
  "reticulate", 
  "gender", 
  "stringr", 
  "caret", 
  "textstem", 
  "tm", 
  "tidytext", 
  "lhs", 
  "smoof", 
  "mlrMBO", 
  "DiceKriging", 
  "mice", 
  "parallel", 
  "forcats", 
  "Boruta", 
  "textfeatures", 
  "cluster", 
  "fpc", 
  "dbscan", 
  "GGally", 
  "reshape2")
load_pkgs(pkg_list)

load_helper_func()
load_tf_gpu_env()

seed <- 123
saveProcessedData <- F
cores <- detectCores() - 1
```

## Read Provided Data

The provided data is broken down to two separate files, one for training, of which contain a price column, and a scoring data set that does not have the price column. 

```{r warning=FALSE}
writeSubmit <- function(pred) {
  submissionFile = data.frame(id = scoringData$id, price = pred)
  write.csv(submissionFile, 'submission.csv', row.names = F)
}

rawData <- read_csv('./input/rentlala2021/analysisData.csv')

scoringData <- read_csv('./input/rentlala2021/scoringData.csv')

```

### Correcting column data type 

By doing some column comparison, we can see that two data sets contains columns that does not match each other. Thus, some preliminary house keeping is needed to keep all columns in two data set in sync. 

```{r}

compare_df_cols(rawData, scoringData) %>%
  filter(rawData != scoringData |
           rawData %>% is.na() | scoringData %>% is.na())

rawData %>% mutate(license = license %>% as.logical()) -> rawData
scoringData  %>% mutate(zipcode = zipcode %>% as.numeric()) -> scoringData

compare_df_cols(rawData, scoringData) %>%
  filter(rawData != scoringData | rawData %>% is.na() | scoringData %>% is.na())
```

### Merging scoring data and training data 

The following code will create a price column for the scoring data such that two data sets can bind together as one data set for the upcoming data pre-processing and cleaning. 

```{r}

pricedScoringData <- scoringData %>% mutate(price = -1)

allData <- rawData %>% bind_rows(pricedScoringData) 
```


## Pre-Processing Data

Due to the fact that most models can not handle missing data, character data, or unscaled data, it would be necessary to clean and preprocess data before moving forward. Other than that, it might be helpful to do some feature engineering such that models can have more data to work with. However, considering the fact that most models tend to run longer and perform worse with more feature added, feature selection will be needed to improve model performance and/or accuracy. 

### Grouping Columns with Same Data Type 

Given that there are different data types in the data set, bulk processing columns with the same data type might speed up the process. The following code serves the purpose of putting columns with same data type together to help with later data cleaning. 

```{r warning=FALSE}

# Extract ID column 
extractID <- allData %>% select(id)

allData <- allData %>% select(-id)

# Put similar columns into baskets 
numericCols <- allData %>% select(is.numeric) %>% colnames()
boolCols <- allData %>% select(is.logical) %>% colnames()
dateCols <- allData %>% select(is.Date) %>% colnames()
charCols <- allData %>% select(is.character) %>% colnames()
longCharCols <-
  allData[charCols] %>% 
  select(c(name, 
      summary, 
      space, 
      description, 
      neighborhood_overview, 
      notes, 
      transit, 
      access, 
      interaction, 
      house_rules, 
      host_about
  )) %>% 
  colnames()
factorCharCols <- 
  allData[charCols] %>% 
  select(-c(name, 
      summary, 
      space, 
      description, 
      neighborhood_overview, 
      notes, 
      transit, 
      access, 
      interaction, 
      house_rules, 
      host_about
  )) %>% 
  select(-c(
    host_name, 
    host_verifications, 
    host_response_time,
    calendar_updated, 
    host_response_rate, 
    host_acceptance_rate, 
    amenities
  )) %>% 
  colnames()

rateCols <- allData %>% 
  select(c(host_response_rate, host_acceptance_rate)) %>% 
  colnames()

# Encode all text columns to UTF-8 
allData[charCols] <- allData[charCols] %>% mutate_all(funs(enc2utf8(.)))

```

### Data Wrangling and Cleaning 

Having the data in various format and type prevents us to extract information from the data. Hence, the following section will help transform some columns such that they will be easier to work with. 

#### Zip code column 

Given that there exists some missing zip codes in the data set, we can fill in those data point with the most common zip code in their corresponding area. 

```{r}
mostCommonZip <- allData %>% 
  select(c(neighbourhood_cleansed, neighbourhood_group_cleansed, city, zipcode)) %>% 
  group_by(neighbourhood_cleansed, zipcode) %>% 
  summarise(count = n()) %>% 
  filter(count == max(count)) %>% 
  ungroup()

getZip <- function(neighbourhood_cleansed){
  mostCommonZip %>% filter(neighbourhood_cleansed == neighbourhood_cleansed) %>% select(zipcode) %>% pull(zipcode)
}

allData <- allData %>% mutate(zipcode = ifelse(is.na(zipcode), getZip(neighbourhood_cleansed), zipcode)) %>% mutate(zipcode = zipcode %>% as.factor())

```

#### Rate columns 

There exists some text columns that are in the percentage format. We can assume that all NA values in these columns are 0, since, in a real world scenario, it's reasonable that theses NA values are derived from dividing 0. For the rest of the data point, we can parse to numeric. 

```{r}

allData[rateCols] <- allData[rateCols] %>% 
  mutate(host_response_rate = gsub("N/A","0%", host_response_rate)) %>% 
  mutate(host_acceptance_rate = gsub("N/A","0%", host_acceptance_rate)) %>% 
  mutate(host_response_rate = gsub("%","", host_response_rate)) %>% 
  mutate(host_acceptance_rate = gsub("%","", host_acceptance_rate)) %>% 
  mutate_all(as.numeric) %>% 
  mutate_each(funs(./100)) %>% 
  replace(is.na(.),0)
```

#### Handle non-char columns NA value  

The following code handles square_feet, weekly_price, and monthly_price columns' NA value. It might not be the best way, but setting these values to 0 is safe. One alternative will be using MISE imputation, but since the number of missing value is too large, it tempers the distribution of these columns. Another way that can be use is to train models that predicts these values. 

```{r}
allData[boolCols] <- allData[boolCols] %>% replace(is.na(.),F)

reservedNumCols <- allData %>% select(c(square_feet, weekly_price, monthly_price)) %>% colnames()

allData[numericCols[numericCols %!in% reservedNumCols]] <- 
  allData[numericCols[numericCols %!in% reservedNumCols]] %>% replace(is.na(.),0)

allData <- allData %>% mutate(square_feet = ifelse(is.na(square_feet), 0, square_feet))
allData <- allData %>% mutate(weekly_price = ifelse(is.na(weekly_price), 0, weekly_price))
allData <- allData %>% mutate(monthly_price = ifelse(is.na(monthly_price), 0, monthly_price))

```

#### Factor columns 

There exists several text columns that can be converted to factors. Some of them are only having one level, so they should be drop. On the other hand, I decided to keep columns with large amount of levels as well, but it would be wise to down size these factors and grouping low frequency factors into other. 

```{r}

allData[factorCharCols] <- allData[factorCharCols] %>%
  replace(is.na(.), "N/A") %>%
  mutate_all(as.factor)

# Exclude 1 level factor columns 
allData <- allData %>% select(-c(country_code, country, state, market)) 

```

#### Host verification and amenities 

For host verification and amenities columns, they are being transformed into one hot dummy columns per each unique items. This will allow models to process information in these two columns easier. The original columns are then dropped after being processed. 

```{r}

# Create verification count column 
allData <- allData %>% 
  mutate(host_verifications = gsub("\\[|\\]|\\'|\\,", "", host_verifications)) %>% 
  mutate(vari_count = strsplit(host_verifications, " ") %>% lengths())

vari_list <- allData %>% 
  select(host_verifications) %>% 
  lapply(function(x) unique(trimws(unlist(strsplit(x, " ")))))

for(w in 1:length(vari_list[[1]])) {
  new <- grepl(pattern = vari_list[[1]][w], x = allData$host_verifications, fixed = TRUE)
  allData[paste(vari_list[[1]][w], "_vari")] <- new
}

# Create amenities count column 
allData <- allData %>% 
  mutate(amenities_count = strsplit(amenities, ",") %>% lengths()) 

amen_list <- allData %>% 
  select(amenities) %>% 
  mutate(amenities = gsub("\\.", "", amenities)) %>% 
  lapply(function(x) unique(trimws(unlist(strsplit(x, ",")))))

for(w in 1:length(amen_list[[1]])) {
  new <- grepl(pattern = amen_list[[1]][w], x = allData$amenities, fixed = TRUE)
  allData[paste(amen_list[[1]][w], "_amen")] <- new
}

# discard original column 
allData <- allData %>% select(-c(amenities, host_verifications)) %>% clean_names()

```

#### Duration columns

Duration columns are messy, since they are all in text format and does not have consistent step size. Therefore after stripping all text component in these columns, a column specific step size is chosen to help rescaling the duration. 

```{r}
allData <- allData %>%
  mutate(host_response_time = gsub("within a ", "", host_response_time)) %>%
  mutate(host_response_time = gsub("within an ", "", host_response_time)) %>%
  mutate(host_response_time = gsub("few hours", "12", host_response_time)) %>%
  mutate(host_response_time = gsub("hour", "1", host_response_time)) %>%
  mutate(host_response_time = gsub("a few days or more", "48", host_response_time)) %>%
  mutate(host_response_time = gsub("day", "24", host_response_time)) %>%
  mutate(host_response_time = replace_na(host_response_time, "N/A")) %>% 
  mutate(host_response_time = gsub("N/A", "96", host_response_time)) %>%
  mutate(host_response_time = as.numeric(host_response_time))

allData <- allData %>% 
  mutate(calendar_updated = gsub(" ago", "", calendar_updated)) %>% 
  mutate(calendar_updated = gsub("today", "0", calendar_updated)) %>% 
  mutate(calendar_updated = gsub("yesterday", "1", calendar_updated)) %>% 
  mutate(calendar_updated = case_when(
    grepl("days", calendar_updated) ~ as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated)) %>% as.character(), 
    grepl("weeks", calendar_updated) ~ as.character(as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated))*7),
    grepl("months", calendar_updated) ~ as.character(as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated))*30), 
    grepl("a week", calendar_updated) ~ "7",
    grepl("week", calendar_updated) ~ "7",
    grepl("never", calendar_updated) ~ "3000",
    TRUE ~ as.character(calendar_updated)
  )) %>% 
  mutate(calendar_updated = as.numeric(calendar_updated))

```

#### Date columns 

Some models can not process date columns, so we need to transform them to numeric. Using the latest date as 0, calculate other dates' "distance" to the most resent date to get a consistent numeric transformation. 

```{r}

allData[dateCols] <- allData %>% 
  select(dateCols) %>% 
  mutate_all(funs(max(., na.rm = TRUE) - .)) %>% 
  mutate_all(as.numeric)

```


### Feature Engneering

Having 90 columns is good, but why not more? Some models will benefit from having more features, especially meaningful features and features that were not created from other numeric features. 

#### Mean price for areas 

Considering that if I as a user on the platform and need to price my property, it would be helpful to know the average price in my area. The same applies to the artificial stupidity, providing an average price for each area is like helping it to cheat on a test, the result might be phenomenal. The following code adds three new columns to the data set: mean price for neighbourhood, for neighbourhood group, and for zip code. 

```{r}
mean_price <- allData %>% 
  filter(price > -1) %>% 
  group_by(neighbourhood_cleansed = neighbourhood_cleansed) %>%
    summarize(record_count_c = n(), 
              price_mean_c = mean(price))

allData <- allData %>% left_join(mean_price, by = c("neighbourhood_cleansed" = "neighbourhood_cleansed"))
allData[is.na(allData$price_mean_c),]$price_mean_c = mean(allData["price" > -1, ]$price_mean_c, na.rm = TRUE)

mean_price2 <- allData %>% 
  filter(price > -1) %>% 
  group_by(neighbourhood_group_cleansed = neighbourhood_group_cleansed) %>%
  summarize(price_mean_ngc = mean(price))

allData <- allData %>% left_join(mean_price2, by = c("neighbourhood_group_cleansed" = "neighbourhood_group_cleansed"))

mean_price3 <- allData %>% 
  filter(price > -1) %>% 
  group_by(zipcode = zipcode) %>%
  summarize(price_mean_zip = mean(price))

allData <- allData %>% left_join(mean_price3, by = c("zipcode" = "zipcode"))
allData[is.na(allData$price_mean_zip),]$price_mean_zip = mean(allData["price" > -1, ]$price_mean_zip, na.rm = TRUE)
```

#### Host Gender

This new feature might be excessive, but I just can't help myself. Knowing an host's name gives the opportunity to guess their gender. Though, it might not be something that influence the price, but who knows, maybe male tends to price their property higher than female. 

```{r}
allData %>% select(host_name) %>% c() -> names 

allData <- allData %>%
  left_join(gender(names$host_name) %>%
              distinct() %>%
              select(c(name, proportion_male, proportion_female)),
            by = c("host_name" = "name"))

```

#### Zip code coordinate

Having the zip code column might not be helpful since they are all just numbers without meanings. Therefore, adding each zip code's coordinate might be something useful. In a real world scenario, it's safe to assume that properties in some areas is priced hiher than other, but it's up to the model to findout. 

```{r}
ZipCodes <- read.table(unz("US.zip","US.txt"), sep="\t")
names(ZipCodes) = c("CountryCode", "zip", "PlaceName", 
"AdminName1", "AdminCode1", "AdminName2", "AdminCode2", 
"AdminName3", "AdminCode3", "latitude", "longitude", "accuracy") 
ZipCodes <- ZipCodes %>% mutate(zip = as.factor(zip))
allData <- allData %>% 
  left_join(
    ZipCodes %>% 
      select(c(zip, 
               PlaceName, 
               AdminName2, 
               latitude, 
               longitude)), by = c("zipcode"="zip")
  )

allData <- allData %>% mutate(PlaceName = PlaceName %>% as.factor(), 
                              AdminName2 = AdminName2 %>% as.factor())

```

#### Text mining 

The fun part is that all these "useless" long text columns can also be transformed to numeric columns. The textfeatures function will generate columns like word count, url count, exclamation mark count, etc. What is even better is that it also generates sentiment analysis and LDA topic clustering analysis on these text columns. Are these columns useful? It's up to the model to find out. 
 
```{r}
allData[longCharCols] <- allData[longCharCols] %>% replace(is.na(.), "")

allText <- NULL
for(col in longCharCols) allText <- paste(allText, " ", allData[[col]])

tex_feat <- textfeatures(allText)
allData <- allData %>% bind_cols(tex_feat)
```

#### Create 2 and 3 power columns 

Assuming that not all features are having leaner relationship with the price, rasing 2 and 3 power to all numeric features might help the model to fit better. 

```{r}
copyData <- allData

allData <- allData %>% cbind( copyData %>%
  select(where(is.numeric)) %>%
  select(-price) %>%
  mutate_all(function(x) x^2) %>%
  setNames(paste0(names(.), "_2pow")))
allData <- allData %>% cbind( copyData %>%
  select(where(is.numeric)) %>%
  select(-price) %>%
  mutate_all(function(x) x^3) %>%
  setNames(paste0(names(.), "_3pow")))
```

#### Scale columns 

Scaling is not necessary for some models, and not all models benifits from scaled data, but here we are, why not. 

```{r warning=FALSE}
numCols <- allData %>% select(is.numeric) %>% colnames()
facCols <- allData %>% select(is.factor) %>% colnames()
boolCols <- allData %>% select(is.logical) %>% colnames()

allData[numCols] <- allData[numCols] %>% 
  replace(is.na(.),0) %>% 
  mutate_at(vars(-price), funs(scale))

allData[facCols] <- allData[facCols] %>%
  mutate_all(funs(as.numeric(.)-1))

allData[boolCols] <- allData[boolCols] %>% 
  mutate_all(funs(as.numeric(.)))
```

#### Remove 0 variance columns 

Zero variance features are meaningless, it's wise to drop them. 

```{r}
remove0var <- function(dat) {
    out <- lapply(dat, function(x) length(unique(x)))
    want <- which(!out > 1)
    name <- unlist(want) %>% names()
    print(name)
    dat %>% select(-all_of(name))
}

allData <- allData %>% remove0var()
```

#### Clustering Data 

Considering rent price can be classified as high, medium, and low price range, let's consider would it be helpful if the model also knows if a property is in which price range? Having this in mind, clustering data might segregate data into different price range. The following code should generates 15 clusters for the data set. Due to the time limit, I just used the simplest clustering method, k-mean, and hand picked the number of cluster. However, HDBSCAN would be a better choice of clustering method in this case. (too bad it runs too long and does not support parallel processing)

```{r}
beforeCluster <- allData 

allData <- beforeCluster %>% select(!is.character)

wss <- (nrow(allData)-1)*sum(apply(allData,2,var))
for (i in 2:20) { # increase for better result 
  set.seed(seed)
  # print(i)
  clu <- kmeans(allData %>% select(-price), centers=i)
  wss[i] <- sum(clu$withinss) 
  }
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")

set.seed(seed)
kc <- kmeans(allData, centers=15)

beforeCluster %>% mutate(cluster = kc$cluster %>% as.factor()) -> afterCluster

```


#### Generate mean price for clusters

Like mean price for areas, haveing the mean price for each cluster might also help the model find the more appropreate price. 

```{r}

mean_price_cluster <- afterCluster %>% 
  filter(price > -1) %>% 
  group_by(cluster = cluster) %>%
  summarize(price_mean_clus = mean(price))

afterCluster <- afterCluster %>% left_join(mean_price_cluster, by = c("cluster" = "cluster"))

# plotting each cluster's price distribution 
pp <- afterCluster %>% select(c(price, cluster)) %>% ggplot(aes(x = price, color = cluster)) + geom_density()
pp %>% ggplotly()

allData <- afterCluster %>% mutate(cluster = cluster %>% as.numeric())

```

### Prepare for modeling

After all data are being cleaned, pre-processed, and transformed, we need to prep it for modeling. 

#### Separate Train and Test 

Training set and testing set are separated. 

```{r}

trainData <- allData %>%
    select(!is.character) %>% 
    filter(price > -1) 
testData <- allData %>%
    select(!is.character) %>% 
    filter(price == -1) %>% select(-price)

```

#### Feature selection

To lighten the load of some models, we can perform a feature selection on our data set. Some models might even perform better with less model. The following code uses boruta algorithm, a tree based model, to calculate feature importance. 

```{r}

boruta_output <-
  Boruta(
    price ~ .,
    data = trainData,
    pValue = 0.05,
    maxRuns = 500,
    doTrace = 2,
    getImp = getImpXgboost, # delete this line for better result, keep it for faster output
    nthread=cores,
  )

boruta_dec <- attStats(boruta_output) %>% rownames_to_column()
boruta_dec[boruta_dec$decision!="Rejected",]

selectedCols <- boruta_output %>% getSelectedAttributes(withTentative = TRUE)


trainData <- trainData %>% select(c(price, selectedCols))
testData <- testData %>% select(selectedCols)

```


#### Save to file (if needed)

```{r}
if (saveProcessedData) {
  
  write.csv(trainData,
            file("processedTrainData.csv",encoding="UTF-8"),
            row.names = F)
  write.csv(testData,
            file("processedTestData.csv",encoding="UTF-8"),
            row.names = F)
}
```

## Modeling 

This is the exciting part, we will use three models to fit our training data and see which one performs the best. 

### Linear Regression 

This is a baseline model, there is really nothing to see here. (the result is eye-burning)

```{r}
linear <- lm(price~., data = trainData)

summary(linear)

prep <- predict(linear, newdata = testData)

# writeSubmit(pred)
```


### XGBoost

XGBoost has a great reputation on kaggle. We will see how it performs on our data set. Instead of grid search, we will be using the Bayes method to find the best hyper parameter set, as it performs faster than grid search and yield better result than randomly selecting hyper parameter values.  

```{r}

# Create training matrix 
BoostTrainData <- xgb.DMatrix(model.matrix(price ~ ., data = trainData),
                              label = as.matrix(trainData %>% select(price)))

```

#### Make objective function

For the Bayes method, we need an objective function that allows the algorithm to collect data/error score on different sets of hyper parameters. Inside of this objective function, each time it runs, an XGboost with 10 fold cv will be run with selected hyper parameter set, the test error score (RMSE) will then be recorded for this specific set of hyper parameter. 
 
```{r}
# objective function for bayes hyperparameter tuning method 
obj.fun <- makeSingleObjectiveFunction(
  # name of the objective function
  name = "xgb_cv_bayes",
  
  # the xgboost function 
  fn =   function(x) {
    set.seed(seed)
    print(x)
    cv <- xgb.cv(
      params = list(
        booster          = "gbtree",
        eta                    = x["eta"],
        max_depth              = x["max_depth"],
        min_child_weight       = x["min_child_weight"],
        gamma                  = x["gamma"],
        lambda                 = x["lambda"],
        alpha                  = x["alpha"],
        subsample              = x["subsample"],
        colsample_bytree       = x["colsample_bytree"],
        max_delta_step         = x["max_delta_step"],
        tweedie_variance_power = x["tweedie_variance_power"],
        objective              = 'reg:tweedie',
        eval_metric            = 'rmse'
      ),
      data = BoostTrainData,
      nround = 7000,
      nthread = cores,
      nfold =  10,
      prediction = FALSE,
      showsd = TRUE,
      early_stopping_rounds = 5,
      verbose = 1,
      print_every_n = 500
    )
    cv$evaluation_log %>% pull(4) %>% min
  },
  
  # hyperparameters 
  par.set = makeParamSet(
    makeNumericParam("eta",                    lower = 0.005, upper = 0.36),
    makeNumericParam("gamma",                  lower = 1,     upper = 8),
    makeNumericParam("lambda",                 lower = 1,     upper = 8),
    makeNumericParam("alpha",                  lower = 1,     upper = 8),
    makeIntegerParam("max_depth",              lower = 2,     upper = 20),
    makeIntegerParam("min_child_weight",       lower = 1,     upper = 2000),
    makeNumericParam("subsample",              lower = 0.01,  upper = 1),
    makeNumericParam("colsample_bytree",       lower = 0.01,  upper = 1),
    makeNumericParam("max_delta_step",         lower = 0,     upper = 10),
    makeNumericParam("tweedie_variance_power", lower = 1,     upper = 2)
  ),
  
  # objective (minimizing rmse)
  minimize = TRUE
)
```

#### Make driver function 

The driver function for the Bayes method is mainly modeling the RMSE with tested hyper parameter sets. It then will iterate the process (run xgboost with more hyper parameter sets) to optimize the model and minimize the objective(test RMSE). Finally it will return the best performing hyper parameter set. 

```{r}
# Driver function 
do_bayes <-
  function(n_design = NULL,
           opt_steps = NULL,
           of = obj.fun,
           seed = seed) {
    set.seed(seed)
    
    des <- generateDesign(n = n_design,
                          par.set = getParamSet(of),
                          fun = lhs::randomLHS)
    
    control <-
      makeMBOControl() %>% setMBOControlTermination(., iters = opt_steps)
    
    # modeling rmse from hyperparameters (actrual driver function)
    run <- mbo(
      fun = of,
      design = des,
      learner = makeLearner(
        "regr.km",
        predict.type = "se",
        covtype = "matern3_2",
        control = list(trace = FALSE)
      ),
      control = control,
      show.info = TRUE
    )
    
    # ploting the bayes result
    opt_plot <- run$opt.path$env$path %>%
      mutate(Round = row_number()) %>%
      mutate(type = case_when(Round <= n_design ~ "Design",
                              TRUE ~ "mlrMBO optimization")) %>%
      ggplot(aes(x = Round, y = y, color = type)) +
      geom_point() +
      labs(title = "mlrMBO optimization") +
      ylab("-log(likelihood)")
    
    return(list(run = run, plot = opt_plot))
  }
```

#### Run Bayes Run 

Enough talking, the following code runs the Bayes method to tune the XGBoost model. After it finish tuning, the best performing hyper parameter set will be used to generate the final model for sumission. 

```{r}

# Let's go!!! 
# with 20 initial runs that will be used to create model and follow with another 5 runs to optimize the model, and lastly the best hyper parameter set will be generated (increase these numbers to yield better result)
runs <-
  do_bayes(
    n_design = 15, # 500
    of = obj.fun,
    opt_steps = 5, # 1000
    seed = seed
  )

plot(runs$run)

best.params <- runs$run$x

# run the model with the best hyperparamerter set
set.seed(seed)
optimal.cv <- xgb.cv(
  params = best.params,
  data = BoostTrainData,
  nround = 7000,
  nthread = cores,
  nfold =  10,
  prediction = FALSE,
  showsd = TRUE,
  early_stopping_rounds = 5,
  verbose = 1,
  print_every_n = 100, 
  objective = 'reg:tweedie',
  eval_metric = 'rmse'
)

# make the final model
set.seed(seed)
model <-
  xgboost(
    params = best.params,
    data = BoostTrainData,
    nrounds = optimal.cv$best_ntreelimit
  )

# take a peek
summary(model)



```

#### Write submission

```{r}
# predict 
pred <-
  predict(model, model.matrix(price~., testData %>% mutate(price = -1)) %>% xgb.DMatrix())

# make submission csv
# writeSubmit(pred)
```


### ANN

This is truly an artificial stupidity. (Such a shame)

#### Build Net

```{r warning=FALSE}

NetTrainX <- trainData %>% select(-price) %>% as.matrix() 
NetTrainY <- trainData %>% select(price) %>% as.matrix()

inputSize <- dim(NetTrainX)[2] 
offsetSize <- 0.45
dropout <- 0.5
activate <- "relu"

scaleSize <- inputSize * offsetSize

model <- keras_model_sequential() %>%
  layer_dense(units = scaleSize*2, activation = activate, input_shape = dim(NetTrainX)[2]) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*4, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*8, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*4, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*2, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*0.5, activation = activate) %>%
  layer_dense(units = scaleSize*0.25, activation = activate) %>%
  layer_dense(units = 1, activation = activate)

model %>% compile(
   loss = "mse",
   optimizer =  "nadam", 
   metrics = c("mape","mse")
 )
 
model %>% summary()
```

#### Train Net

```{r}
set.seed(seed)
model %>% fit(
  NetTrainX,
  NetTrainY,
  epochs = 20, # change to make it think longer
  batch_size = 128,
  validation_split = 0.2,
  verbose = 2
)

scores <- model %>% evaluate(NetTrainX, NetTrainY, verbose = 0)
print(scores)
```

#### Write submission

```{r}
summary(model)

pred <- predict(model, testData %>% as.matrix())

# writeSubmit(pred)
```

### Conclusion 

In conclusion, there are still so much room for improvement, like outlier handling, better NA value handling, or better clustering method. If time is permitted, it might be better to manually implement the essemble learning process for xgboost and mixing it with random forest (just a thought, might need years to get it done). Other than that, the current model (the one that produces best RMSE on kaggle) takes too long to run (about 3 days) and most of the time are wasted on feature selection, finding the most cluster number, and tuning XGBoost. 

