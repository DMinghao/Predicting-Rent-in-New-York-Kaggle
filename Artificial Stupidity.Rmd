---
title: "Artificial Stupidity"
author: "Minghao Du"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Initiating R Environment 

```{r echo=FALSE}
rm(list = ls())
gc()

downloader::source_url("https://raw.githubusercontent.com/DMinghao/Analysis_Pocketknife/main/R/init_env.R", downloader::sha_url("https://raw.githubusercontent.com/DMinghao/Analysis_Pocketknife/main/R/init_env.R"))

pkg_list <- c(
  "plotly", 
  "tidyverse", 
  "readxl", 
  "GGally", 
  "psych", 
  "janitor", 
  "e1071", 
  "lubridate", 
  "fastDummies", 
  "xgboost", 
  "tensorflow", 
  "keras", 
  "reticulate", 
  "gender", 
  "stringr", 
  "caret", 
  "textstem", 
  "tm", 
  "tidytext", 
  "lhs", 
  "smoof", 
  "mlrMBO", 
  "DiceKriging", 
  "mice", 
  "parallel", 
  "forcats", 
  "Boruta", 
  "textfeatures", 
  "cluster", 
  "fpc", 
  "dbscan", 
  "GGally")
load_pkgs(pkg_list)

load_helper_func()
load_tf_gpu_env()

seed <- 123
saveProcessedData <- F
cores <- detectCores() - 1
```

## Read Provided Data

```{r}
writeSubmit <- function(pred) {
  submissionFile = data.frame(id = scoringData$id, price = pred)
  write.csv(submissionFile, 'submission.csv', row.names = F)
}

rawData <- read_csv('./input/rentlala2021/analysisData.csv')

scoringData <- read_csv('./input/rentlala2021/scoringData.csv')

```

### Correcting column data type 

```{r}

compare_df_cols(rawData, scoringData) %>%
  filter(rawData != scoringData |
           rawData %>% is.na() | scoringData %>% is.na())

rawData %>% mutate(license = license %>% as.logical()) -> rawData
scoringData  %>% mutate(zipcode = zipcode %>% as.numeric()) -> scoringData

compare_df_cols(rawData, scoringData) %>%
  filter(rawData != scoringData | rawData %>% is.na() | scoringData %>% is.na())
```

### Merging scoring data and training data 

```{r}

pricedScoringData <- scoringData %>% mutate(price = -1)

allData <- rawData %>% bind_rows(pricedScoringData) 
```


## Pre-Processing Data


### Grouping Columns with Same Data Type 

```{r}

# Extract ID column 
extractID <- allData %>% select(id)

allData <- allData %>% select(-id)

# Put similar columns into baskets 
numericCols <- allData %>% select(is.numeric) %>% colnames()
boolCols <- allData %>% select(is.logical) %>% colnames()
dateCols <- allData %>% select(is.Date) %>% colnames()
charCols <- allData %>% select(is.character) %>% colnames()
longCharCols <-
  allData[charCols] %>% 
  select(c(name, 
      summary, 
      space, 
      description, 
      neighborhood_overview, 
      notes, 
      transit, 
      access, 
      interaction, 
      house_rules, 
      host_about
  )) %>% 
  colnames()
factorCharCols <- 
  allData[charCols] %>% 
  select(-c(name, 
      summary, 
      space, 
      description, 
      neighborhood_overview, 
      notes, 
      transit, 
      access, 
      interaction, 
      house_rules, 
      host_about
  )) %>% 
  select(-c(
    host_name, 
    host_verifications, 
    host_response_time,
    calendar_updated, 
    host_response_rate, 
    host_acceptance_rate, 
    amenities
  )) %>% 
  colnames()

rateCols <- allData %>% 
  select(c(host_response_rate, host_acceptance_rate)) %>% 
  colnames()

# Encode all text columns to UTF-8 
allData[charCols] <- allData[charCols] %>% mutate_all(funs(enc2utf8(.)))

```

### Data Wrangling and Cleaning 

#### Zip code column 

```{r}
mostCommonZip <- allData %>% 
  select(c(neighbourhood_cleansed, neighbourhood_group_cleansed, city, zipcode)) %>% 
  group_by(neighbourhood_cleansed, zipcode) %>% 
  summarise(count = n()) %>% 
  filter(count == max(count)) %>% 
  ungroup()

getZip <- function(neighbourhood_cleansed){
  mostCommonZip %>% filter(neighbourhood_cleansed == neighbourhood_cleansed) %>% select(zipcode) %>% pull(zipcode)
}

allData <- allData %>% mutate(zipcode = ifelse(is.na(zipcode), getZip(neighbourhood_cleansed), zipcode)) %>% mutate(zipcode = zipcode %>% as.factor())

```

#### Rate columns 

```{r}

allData[rateCols] <- allData[rateCols] %>% 
  mutate(host_response_rate = gsub("N/A","0%", host_response_rate)) %>% 
  mutate(host_acceptance_rate = gsub("N/A","0%", host_acceptance_rate)) %>% 
  mutate(host_response_rate = gsub("%","", host_response_rate)) %>% 
  mutate(host_acceptance_rate = gsub("%","", host_acceptance_rate)) %>% 
  mutate_all(as.numeric) %>% 
  mutate_each(funs(./100)) %>% 
  replace(is.na(.),0)
```

#### Handle non-char columns NA value  

```{r}
allData[boolCols] <- allData[boolCols] %>% replace(is.na(.),F)

reservedNumCols <- allData %>% select(c(square_feet, weekly_price, monthly_price)) %>% colnames()

allData[numericCols[numericCols %!in% reservedNumCols]] <- 
  allData[numericCols[numericCols %!in% reservedNumCols]] %>% replace(is.na(.),0)

allData <- allData %>% mutate(square_feet = ifelse(is.na(square_feet), 0, square_feet))
allData <- allData %>% mutate(weekly_price = ifelse(is.na(weekly_price), 0, weekly_price))
allData <- allData %>% mutate(monthly_price = ifelse(is.na(monthly_price), 0, monthly_price))

```

#### Factor columns 

```{r}

allData[factorCharCols] <- allData[factorCharCols] %>%
  replace(is.na(.), "N/A") %>%
  mutate_all(as.factor)

# Exclude 1 level factor columns 
allData <- allData %>% select(-c(country_code, country, state, market)) 

```

#### Host verification and amenities 

```{r}

# Create verification count column 
allData <- allData %>% 
  mutate(host_verifications = gsub("\\[|\\]|\\'|\\,", "", host_verifications)) %>% 
  mutate(vari_count = strsplit(host_verifications, " ") %>% lengths())

vari_list <- allData %>% 
  select(host_verifications) %>% 
  lapply(function(x) unique(trimws(unlist(strsplit(x, " ")))))

for(w in 1:length(vari_list[[1]])) {
  new <- grepl(pattern = vari_list[[1]][w], x = allData$host_verifications, fixed = TRUE)
  allData[paste(vari_list[[1]][w], "_vari")] <- new
}

# Create amenities count column 
allData <- allData %>% 
  mutate(amenities_count = strsplit(amenities, ",") %>% lengths()) 

amen_list <- allData %>% 
  select(amenities) %>% 
  mutate(amenities = gsub("\\.", "", amenities)) %>% 
  lapply(function(x) unique(trimws(unlist(strsplit(x, ",")))))

for(w in 1:length(amen_list[[1]])) {
  new <- grepl(pattern = amen_list[[1]][w], x = allData$amenities, fixed = TRUE)
  allData[paste(amen_list[[1]][w], "_amen")] <- new
}

# discard original column 
allData <- allData %>% select(-c(amenities, host_verifications)) %>% clean_names()

```

#### Duration columns

```{r}
allData <- allData %>%
  mutate(host_response_time = gsub("within a ", "", host_response_time)) %>%
  mutate(host_response_time = gsub("within an ", "", host_response_time)) %>%
  mutate(host_response_time = gsub("few hours", "12", host_response_time)) %>%
  mutate(host_response_time = gsub("hour", "1", host_response_time)) %>%
  mutate(host_response_time = gsub("a few days or more", "48", host_response_time)) %>%
  mutate(host_response_time = gsub("day", "24", host_response_time)) %>%
  mutate(host_response_time = replace_na(host_response_time, "N/A")) %>% 
  mutate(host_response_time = gsub("N/A", "96", host_response_time)) %>%
  mutate(host_response_time = as.numeric(host_response_time))

allData <- allData %>% 
  mutate(calendar_updated = gsub(" ago", "", calendar_updated)) %>% 
  mutate(calendar_updated = gsub("today", "0", calendar_updated)) %>% 
  mutate(calendar_updated = gsub("yesterday", "1", calendar_updated)) %>% 
  mutate(calendar_updated = case_when(
    grepl("days", calendar_updated) ~ as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated)) %>% as.character(), 
    grepl("weeks", calendar_updated) ~ as.character(as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated))*7),
    grepl("months", calendar_updated) ~ as.character(as.numeric(gsub("([0-9]+).*$", "\\1", calendar_updated))*30), 
    grepl("a week", calendar_updated) ~ "7",
    grepl("week", calendar_updated) ~ "7",
    grepl("never", calendar_updated) ~ "3000",
    TRUE ~ as.character(calendar_updated)
  )) %>% 
  mutate(calendar_updated = as.numeric(calendar_updated))

```

#### Date columns 

```{r}

allData[dateCols] <- allData %>% 
  select(dateCols) %>% 
  mutate_all(funs(max(., na.rm = TRUE) - .)) %>% 
  mutate_all(as.numeric)

```


### Feature Engneering

#### Mean price for areas 

```{r}
mean_price <- allData %>% 
  filter(price > -1) %>% 
  group_by(neighbourhood_cleansed = neighbourhood_cleansed) %>%
    summarize(record_count_c = n(), 
              price_mean_c = mean(price))

allData <- allData %>% left_join(mean_price, by = c("neighbourhood_cleansed" = "neighbourhood_cleansed"))
allData[is.na(allData$price_mean_c),]$price_mean_c = mean(allData["price" > -1, ]$price_mean_c, na.rm = TRUE)

mean_price2 <- allData %>% 
  filter(price > -1) %>% 
  group_by(neighbourhood_group_cleansed = neighbourhood_group_cleansed) %>%
  summarize(price_mean_ngc = mean(price))

allData <- allData %>% left_join(mean_price2, by = c("neighbourhood_group_cleansed" = "neighbourhood_group_cleansed"))

mean_price3 <- allData %>% 
  filter(price > -1) %>% 
  group_by(zipcode = zipcode) %>%
  summarize(price_mean_zip = mean(price))

allData <- allData %>% left_join(mean_price3, by = c("zipcode" = "zipcode"))
allData[is.na(allData$price_mean_zip),]$price_mean_zip = mean(allData["price" > -1, ]$price_mean_zip, na.rm = TRUE)
```

#### Host Gender

```{r}
allData %>% select(host_name) %>% c() -> names 

allData <- allData %>%
  left_join(gender(names$host_name) %>%
              distinct() %>%
              select(c(name, proportion_male, proportion_female)),
            by = c("host_name" = "name"))

```

#### Zip code coordinate

```{r}
ZipCodeSourceFile = "http://download.geonames.org/export/zip/US.zip"
tempFile <- tempfile()
download.file(ZipCodeSourceFile , tempFile)
ZipCodes <- read.table(unz(tempFile, "US.txt"), sep="\t")
unlink(tempFile)
names(ZipCodes) = c("CountryCode", "zip", "PlaceName", 
"AdminName1", "AdminCode1", "AdminName2", "AdminCode2", 
"AdminName3", "AdminCode3", "latitude", "longitude", "accuracy") 
ZipCodes <- ZipCodes %>% mutate(zip = as.factor(zip))
allData <- allData %>% 
  left_join(
    ZipCodes %>% 
      select(c(zip, 
               PlaceName, 
               AdminName2, 
               latitude, 
               longitude)), by = c("zipcode"="zip")
  )

allData <- allData %>% mutate(PlaceName = PlaceName %>% as.factor(), 
                              AdminName2 = AdminName2 %>% as.factor())

```

#### Text mining 

```{r}
allData[longCharCols] <- allData[longCharCols] %>% replace(is.na(.), "")

allText <- NULL
for(col in longCharCols) allText <- paste(allText, " ", allData[[col]])

tex_feat <- textfeatures(allText)
allData <- allData %>% bind_cols(tex_feat)
```

#### Create 2 and 3 power columns 

```{r}
copyData <- allData

allData <- allData %>% cbind( copyData %>%
  select(where(is.numeric)) %>%
  select(-price) %>%
  mutate_all(function(x) x^2) %>%
  setNames(paste0(names(.), "_2pow")))
allData <- allData %>% cbind( copyData %>%
  select(where(is.numeric)) %>%
  select(-price) %>%
  mutate_all(function(x) x^3) %>%
  setNames(paste0(names(.), "_3pow")))
```

#### Scale columns 

```{r}
numCols <- allData %>% select(is.numeric) %>% colnames()
facCols <- allData %>% select(is.factor) %>% colnames()
boolCols <- allData %>% select(is.logical) %>% colnames()

allData[numCols] <- allData[numCols] %>% 
  replace(is.na(.),0) %>% 
  mutate_at(vars(-price), funs(scale))

allData[facCols] <- allData[facCols] %>%
  mutate_all(funs(as.numeric(.)-1))

allData[boolCols] <- allData[boolCols] %>% 
  mutate_all(funs(as.numeric(.)))
```

#### Remove 0 variance columns 

```{r}
remove0var <- function(dat) {
    out <- lapply(dat, function(x) length(unique(x)))
    want <- which(!out > 1)
    name <- unlist(want) %>% names()
    print(name)
    dat %>% select(-name)
}

allData <- allData %>% remove0var() %>% remove0var() 
```

#### Clustering Data 

```{r}

wss <- (nrow(allData)-1)*sum(apply(allData,2,var))
for (i in 2:20) {
  set.seed(seed)
  print(i)
  clu <- kmeans(allData %>% select(-price), centers=i)
  wss[i] <- sum(clu$withinss) 
  }
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") %>% ggplotly()

set.seed(seed)
kc <- kmeans(allData, centers=15)

beforeCluster %>% mutate(cluster = kc$cluster %>% as.factor()) -> afterCluster

```


#### Generate mean price for clusters

```{r}

mean_price_cluster <- afterCluster %>% 
  filter(price > -1) %>% 
  group_by(cluster = cluster) %>%
  summarize(price_mean_clus = mean(price))

afterCluster <- afterCluster %>% left_join(mean_price_cluster, by = c("cluster" = "cluster"))

pp <- afterCluster %>% select(c(price, cluster)) %>% ggplot(aes(x = price, color = cluster)) + geom_density()
pp %>% ggplotly()

allData <- afterCluster %>% mutate(cluster = cluster %>% as.numeric())

```

### Prepare for modeling

#### Separate Train and Test 

```{r}

trainData <- allData %>%
    select(!is.character) %>% 
    filter(price > -1) 
testData <- allData %>%
    select(!is.character) %>% 
    filter(price == -1) %>% select(-price)

```

#### Feature selection

```{r}

boruta_output <-
  Boruta(
    price ~ .,
    data = trainData,
    pValue = 0.05,
    maxRuns = 500,
    doTrace = 2,
    getImp = getImpXgboost, 
    nthread=cores,
  )

boruta_dec <- attStats(boruta_output)
boruta_dec[boruta_dec$decision!="Rejected",]

#get the names of each feature
imp_features <- row.names(boruta_dec)[which(boruta_dec$decision!="Rejected")]
#get feature importance history
boruta.imp.df <- as.data.frame(xgb.brouta$ImpHistory)
#keep only confirmed and tentative features
boruta.imp.df <- boruta.imp.df[,names(boruta.imp.df)%in%imp_features]
#transform the data to a data frame with two columns: feature and importance value
boruta.imp.df <- melt(boruta.imp.df)
#create a data frame by adding the decision for each feature as well
boruta.imp.df <- cbind.data.frame(boruta.imp.df, 
                               decision=boruta.df$decision[match(boruta.imp.df$variable, 
                                                                 row.names(boruta.df))])
#reorder features data frame by the importance median value
feature_order <- with(boruta.imp.df, reorder(variable, value, median, order = TRUE))
boruta.imp.df$variable <- factor(boruta.imp.df$variable, levels = levels(feature_order))

selectedCols <- boruta_output %>% getSelectedAttributes(withTentative = TRUE)

trainData <- trainData %>% select(c(price, selectedCols))
testData <- testData %>% select(selectedCols)



```


#### Save to file (if needed)

```{r}
if (saveProcessedData) {
  
  write.csv(trainData,
            file("processedTrainData.csv",encoding="UTF-8"),
            row.names = F)
  write.csv(testData,
            file("processedTestData.csv",encoding="UTF-8"),
            row.names = F)
}
```

## Modeling 

### XGBoost

```{r}

# Create training matrix 
BoostTrainData <- xgb.DMatrix(model.matrix(price ~ ., data = trainData),
                              label = as.matrix(trainData %>% select(price)))

```

#### Make objective function

```{r}
# objective function for bayes hyperparameter tuning method 
obj.fun <- makeSingleObjectiveFunction(
  # name of the objective function
  name = "xgb_cv_bayes",
  
  # the xgboost function 
  fn =   function(x) {
    set.seed(seed)
    print(x)
    cv <- xgb.cv(
      params = list(
        # booster          = "gbtree",
        eta                    = x["eta"],
        max_depth              = x["max_depth"],
        min_child_weight       = x["min_child_weight"],
        gamma                  = x["gamma"],
        lambda                 = x["lambda"],
        alpha                  = x["alpha"],
        subsample              = x["subsample"],
        colsample_bytree       = x["colsample_bytree"],
        max_delta_step         = x["max_delta_step"],
        tweedie_variance_power = x["tweedie_variance_power"],
        objective              = 'reg:tweedie',
        eval_metric            = 'rmse'
      ),
      data = BoostTrainData,
      nround = 7000,
      nthread = cores,
      nfold =  10,
      prediction = FALSE,
      showsd = TRUE,
      early_stopping_rounds = 5,
      verbose = 1,
      print_every_n = 500
    )
    cv$evaluation_log %>% pull(4) %>% min
  },
  
  # hyperparameters 
  par.set = makeParamSet(
    makeNumericParam("eta",                    lower = 0.005, upper = 0.36),
    makeNumericParam("gamma",                  lower = 1,     upper = 8),
    makeNumericParam("lambda",                 lower = 1,     upper = 8),
    makeNumericParam("alpha",                  lower = 1,     upper = 8),
    makeIntegerParam("max_depth",              lower = 2,     upper = 20),
    makeIntegerParam("min_child_weight",       lower = 1,     upper = 2000),
    makeNumericParam("subsample",              lower = 0.01,  upper = 1),
    makeNumericParam("colsample_bytree",       lower = 0.01,  upper = 1),
    makeNumericParam("max_delta_step",         lower = 0,     upper = 10),
    makeNumericParam("tweedie_variance_power", lower = 1,     upper = 2)
  ),
  
  # objective (minimizing rmse)
  minimize = TRUE
)
```

#### Make driver function 

```{r}
# Driver function 
do_bayes <-
  function(n_design = NULL,
           opt_steps = NULL,
           of = obj.fun,
           seed = seed) {
    set.seed(seed)
    
    des <- generateDesign(n = n_design,
                          par.set = getParamSet(of),
                          fun = lhs::randomLHS)
    
    control <-
      makeMBOControl() %>% setMBOControlTermination(., iters = opt_steps)
    
    # modeling rmse from hyperparameters (actrual driver function)
    run <- mbo(
      fun = of,
      design = des,
      learner = makeLearner(
        "regr.km",
        predict.type = "se",
        covtype = "matern3_2",
        control = list(trace = FALSE)
      ),
      control = control,
      show.info = TRUE
    )
    
    # ploting the bayes result
    opt_plot <- run$opt.path$env$path %>%
      mutate(Round = row_number()) %>%
      mutate(type = case_when(Round <= n_design ~ "Design",
                              TRUE ~ "mlrMBO optimization")) %>%
      ggplot(aes(x = Round, y = y, color = type)) +
      geom_point() +
      labs(title = "mlrMBO optimization") +
      ylab("-log(likelihood)")
    
    return(list(run = run, plot = opt_plot))
  }
```

#### 

```{r}

# Let's go!!! 
runs <-
  do_bayes(
    n_design = 20,
    of = obj.fun,
    opt_steps = 20,
    seed = seed
  )

plot(runs$run)

best.params <- runs$run$x

# run the model with the best hyperparamerter set
set.seed(seed)
optimal.cv <- xgb.cv(
  params = best.params,
  data = BoostTrainData,
  nround = 7000,
  nthread = cores,
  nfold =  10,
  prediction = FALSE,
  showsd = TRUE,
  early_stopping_rounds = 5,
  verbose = 1,
  print_every_n = 100, 
  objective = 'reg:tweedie',
  eval_metric = 'rmse'
)

# make the final model
set.seed(seed)
model <-
  xgboost(
    params = best.params,
    data = BoostTrainData,
    nrounds = optimal.cv$best_ntreelimit
  )

# take a peek
summary(model)



```

#### Write submission

```{r}
# predict 
pred <-
  predict(model, model.matrix(price~., testData %>% mutate(price = -1)) %>% xgb.DMatrix())

# make submission csv
writeSubmit(pred)
```


### ANN

#### Build Net

```{r}

NetTrainX <- trainData %>% select(-price) %>% as.matrix() 
NetTrainY <- trainData %>% select(price) %>% as.matrix()

inputSize <- dim(NetTrainX)[2] 
offsetSize <- 0.45
dropout <- 0.5
activate <- "relu"

scaleSize <- inputSize * offsetSize

model <- keras_model_sequential() %>%
  layer_dense(units = scaleSize*2, activation = activate, input_shape = dim(NetTrainX)[2]) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*4, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*8, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*4, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*2, activation = activate) %>%
  layer_dropout(rate = dropout) %>%
  layer_dense(units = scaleSize*0.5, activation = activate) %>%
  layer_dense(units = scaleSize*0.25, activation = activate) %>%
  layer_dense(units = 1, activation = activate)

model %>% compile(
   loss = "mse",
   optimizer =  "nadam", 
   metrics = c("mape","mse")
 )
 
model %>% summary()
```

#### Train Net

```{r}
set.seed(seed)
model %>% fit(NetTrainX, NetTrainY, epochs = 100, batch_size = 128, validation_split = 0.2,verbose = 2)
 
scores <- model %>% evaluate(NetTrainX, NetTrainY, verbose = 0)
print(scores)
```

#### Write submission

```{r}
summary(model)

pred <- predict(model, testData %>% as.matrix())

writeSubmit(pred)
```

### Conclusion 

```{r}

```



